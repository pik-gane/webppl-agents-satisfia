// run via  webppl --require webppl-dp --require . examples/runVerySimpleGW.wppl

var env = getEnv(),
    argv = env.argv,
    params = extend({
      // some env-specific parameter settings
    }, argv),
    options = extend({
//      debug: true
      // some env-specific option settings
    }, argv),
    mdp = VerySimpleGW(argv.gw || "GW2", argv.gwparms, argv.time, argv.timeOutDelta),
    world = mdp.world,
    transition = world.transition,
    expectedDelta = mdp.expectedDelta,
    uninformedPolicy = mdp.uninformedPolicy,
    referencePolicy = mdp.referencePolicy,
    startState = mdp.startState,
    aleph0 = argv.aleph0 || mdp.aleph0,
    agent = makeMDPAgentSatisfia(extend(params, {
      expectedDelta, uninformedPolicy, referencePolicy, aleph0, options
    }), world),
    localPolicy = agent.localPolicy, 
    propagateAspiration = agent.propagateAspiration,
    getAspiration4state = agent.getAspiration4state, 
    V = agent.V, 
    V2 = agent.V2,
    entropy = agent.behaviorEntropy_state, 
    KLdiv = agent.behaviorKLdiv_state,
    messingPotential = agent.messingPotential_state,
    cupLoss = agent.cupLoss_state;

// Generate and draw a trajectory:
var simulate = function(state, aleph, _t) {
  var t = _t ? _t : 0,
      aleph4state = asInterval(aleph);
  if (options.verbose || options.debug) console.log(pad(state),"SIMULATE, t",t,"state",prettyState(state),"aleph4state",aleph4state,"...");
  var localPolicy = localPolicy(state, aleph4state),
      actionAndAleph = sample(localPolicy),
      action = actionAndAleph[0], 
      aleph4action = actionAndAleph[1],
      Edel = expectedDelta(state, action);
  var stepData = {state, aleph4state, action, aleph4action, Edel};
  if (state.terminateAfterAction) {
    if (options.verbose || options.debug) console.log(pad(state),"SIMULATE, t",t,"state",prettyState(state),"aleph4state",aleph4state,": localPolicy",JSON.stringify(localPolicy.params),"\n"+pad(state),"| action",action,"aleph4action",aleph4action,"Edel",Edel,"(terminal)");
    return { 
      trajectory: [stepData], // sequence of [state, action] pairs
      conditionalExpectedIndicator: Edel // expected indicator conditional on this trajectory
    };
  } else {
    var nextState = transition(state, action),
        nextAleph4state = propagateAspiration(state, action, aleph4action, Edel, nextState);
    if (options.verbose || options.debug) console.log(pad(state),"SIMULATE, t",t,"state",prettyState(state),"aleph4state",aleph4state,": localPolicy",JSON.stringify(localPolicy.params),"\n"+pad(state),"| action",action,"aleph4action",aleph4action,"Edel",Edel,"nextState",prettyState(nextState),"nextAleph4state",nextAleph4state);
    var nextOut = simulate(nextState, nextAleph4state, t+1);
    return { 
      trajectory: [stepData].concat(nextOut.trajectory), 
      conditionalExpectedIndicator: Edel + nextOut.conditionalExpectedIndicator
    };
  }
};

console.log("aleph0", asInterval(aleph0));

var t0 =  webpplAgents.time();
// verify meeting of expectations:
console.log("V", V(startState, aleph0));
console.log("TIME:", webpplAgents.time() - t0, "ms");
console.log("cupLoss", cupLoss(mdp.startState, aleph0));
console.log("entropy", entropy(mdp.startState, aleph0));
console.log("KLdiv", KLdiv(mdp.startState, aleph0));
console.log("messPot", messingPotential(mdp.startState, aleph0));

var gd = agent.getData, agentData = gd();

// estimate distribution of trajectories:

var infered = Infer({ model() {
  return simulate(mdp.startState, aleph0).trajectory;
}});

console.log("\nDATA FOR REGRESSION TESTS: \n");
console.log(
  webpplAgents.debug.inspect(
    webpplAgents.debug.trajectoriesDistribution.diagrams.forward(infered),
    { colors: true, depth: Number.MAX_SAFE_INTEGER }
  )
)
console.log("END OF DATA FOR REGRESSION TESTS\n");

var trajDist = infered.getDist()
var trajData = trajDist2TrajData(trajDist, agent);

//console.log("trajData", trajData);

var locActionData = webpplAgents.trajDist2LocActionData(trajDist, trajData);
console.log("locActionData", locActionData);

console.log("\nminAdmissibleQ:");
console.log(stateActionFct2ASCII(agent.minAdmissibleQ, agentData.stateActionPairs));
console.log("\nmaxAdmissibleQ:");
console.log(stateActionFct2ASCII(agent.maxAdmissibleQ, agentData.stateActionPairs));

console.log("\nQ:");
console.log(webpplAgents.locActionData2ASCII(locActionData.Q));
console.log("\ncupLoss:");
console.log(webpplAgents.locActionData2ASCII(locActionData.cupLoss));
console.log("\nmessingPotential:");
console.log(webpplAgents.locActionData2ASCII(locActionData.messingPotential));
console.log("\ncombinedLoss:");
console.log(webpplAgents.locActionData2ASCII(locActionData.combinedLoss));

console.log("\naction frequencies:");
console.log(webpplAgents.locActionData2ASCII(locActionData.actionFrequency));



